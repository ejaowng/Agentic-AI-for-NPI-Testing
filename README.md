# Agentic-AI-for-NPI-Testing

A cognitive layer is introduced to abstract the complexity of test and troubleshooting implementations, making the process more intuitive. Additionally, expert input (human-in-the-loop) is integrated to enhance data quality and accuracy. The test execution is entirely based on natural language descriptions.

To run the system, a physical test chamber with CRGNB/MSRBS and a UE connected inside the chamber is required.

We used SWI-Prolog version 9.0.4, installed on an Ubuntu Linux virtual machine. The following commands were used to set up SWI-Prolog:

sudo apt update

sudo apt install ninja-build

sudo apt install build-essential

sudo apt install libx11-dev libxt-dev libxft-dev libjpeg-dev libxpm-dev libtiff-dev libgtk-3-dev tcl-dev tk-dev

git clone --recurse-submodules https://github.com/SWI-Prolog/swipl-devel.git

cd swipl-devel

git checkout V9.0.4

git submodule update --init --recursive

mkdir build && cd build

sudo apt update

sudo apt install gcc-9 g++-9

cmake .. -G Ninja -DCMAKE_C_COMPILER=gcc-9 -DCMAKE_CXX_COMPILER=g++-9 -DSWIPL_PACKAGES_GMP=OFF -DUSE_GMP=OFF -DINSTALL_DOCUMENTATION=OFF ninja

An external built-in has been used for automation. The following commands are used to compile the external built-in:

cd ~/swipl-devel/build/src

export SWIPL_CC=gcc-9

export SWIPL_CXX=g++-9

./swipl-ld -shared -o test_cpp ../../packages/cpp/test_cpp10_7.cpp

To run SWI-Prolog to monitor files generated in the predefined directory (the files are generated by the LLM):

cd ..

./src/swipl -s watch2.pl -g init_watch

To run a prompt on the LLM:

sudo apt update

sudo apt install python3-venv -y

cd ~/LLM

python3 -m venv venv

source venv/bin/activate

pip install --upgrade pip

pip install openai

pip install azure-identity

python3 chat2.py --file ./0_Inst_3.txt

0_Inst_3.txt, located in the LLM folder, contains the knowledge base. Other files—including the lab description, basic pre-test checks, test configuration, and test execution instructions—will be copied and used as a prompt for the LLM, which will convert them into executable code.
